---
layout: post
title: "工作随笔"
date: 2020-02-23 21:10:05 +0800
---

## 效率提升

### 自动化测试

#### 前台自动化测试

python+selenium

验证基本功能及保存验证截图

前台单元测试如何做？？

#### 后台自动化测试

通过ssh+config+shell+sql+sftp等操作预制数据，调用curl命令调用restful接口，并验证结果。自动输出验证报告。

每人掌握快速验证的方法，轮流验证

目前DIM后台已经做到快速验证，其他人补齐到优化改进中

- [x] DIMService   --pengbo
- [ ] SMAP  --liuhuiling
- [ ] RMConsumer   --fanyue
- [ ] SDNBase   --zhujinhui
- [ ] SOConfigService   --hezhengjian

**组内拉通技能**

### 常用开发工具使用

#### git

git 命令号+图形化 tortoisegit/eclipse/IDEA  不推荐使用中文翻译版

#### 静态检查插件

云龙静态检查插件本地化，提交代码前运行，清理。

#### IDE

常用快捷件的熟练使用，重构/格式化/异常处理

##### 宏Macro

将重复性的输入的内容，保存为宏。

### 静态检查清理

参考薛耕的统计邮件，流水线结束后自动发出责任田内，未达标的项，提醒定时清理。

- [ ] 静态检查清理工具提醒    --段强强？

### 流水线整合

微服务包流水线整合，多分支可以使用同一流水线和不同Job来区分，不允许新建多条，尽可能的重用job中的任务

服务包目前没有研究是否可以共用，可以出多个。云龙登记的时候使用tag方式，方便大家查找。



## 分布式锁

同一台机器间可以通过lock来加锁，不同机器只能通过分布式锁来处理。

常用实现方式：**db**、**redis**、**zookeeper**

不管怎么样，分布式的锁服务需要有以下几个特点。

- **安全性（Safety）**：在任意时刻，只有一个客户端可以获得锁（排他性）。
- **避免死锁**：客户端最终一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达。
- **容错性**：只要锁服务集群中的大部分节点存活，客户端就可以进行加锁解锁操作。

### 数据库实现

```sql
update lock set flag = 1 where flag = 0 and resource_key = 'resource_key';
```

如果设置成功之后会返回1，1代表成功更新的条数

如果仅仅是数据的更新，可以使用乐观锁的机制。

```sql
update store set num = $num where id = $id and num = $query_num;
```

#### 应用例子

业务A有share_a，share_b，share_c，A_d，A_e，A_f六个资源。

业务B有share_a，share_b，share_c，B_d，B_e，B_f六个资源。

A和B同时执行的时候，共享资源只能先由一个业务操作之后，再给其他资源使用。

首先开启@transactional确保获取锁是在一个事务中。

- 先查询锁表是否存在共享资源
- 不存在做共享资源的插入，如果另外一个进程也在做插入操作，已经有数据那就会报错，导致事务回滚。
- 如果插入成功（插入后要校验插入的条数是否为3）flag为1。
- 如果存在就使用update语句去更新flag为0的记录。会返回执行成功的条数，我们对比是否为3来判读是否成功争取到锁，如果没有则回滚，随机时间后做重试。

处理过程中，定时刷新updatetime。如果发现updatetime超过3分钟，就判断之前获得锁的这个业务应该已经断联，需要把这个所释放掉。其他业务就可以去获得这个锁，并进行业务的操作。

| resource | owner | flag | updatetime         |
| -------- | ----- | ---- | ------------------ |
| share_a  | A     | 1    | 2020-2-23 21:36:46 |
| share_b  | A     | 1    | 2020-2-23 21:36:46 |
| share_c  | A     | 1    | 2020-2-23 21:36:46 |



### Redis分布式锁

实现Redis分布式锁的最简单的方法就是在Redis中创建一个key，这个key有一个失效时间，以保证锁最终会被自动释放掉。当客户端释放资源(解锁）的时候，会删除掉这个key。

```powershell
 SET resource_name my_random_value NX PX 30000
```

这个命令仅在不存在key的时候才能被执行成功（NX选项），并且这个key有一个30秒的自动失效时间（PX属性）。这个key的值是“my_random_value”(一个随机值），这个值在所有的客户端必须是唯一的，所有同一key的获取者（竞争者）这个值都不能一样。

value的值必须是随机数主要是为了更安全的释放锁，释放锁的时候使用脚本告诉Redis:只有key存在并且存储的值和我指定的值一样才能告诉我删除成功。可以通过以下Lua脚本实现

```lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

使用这种方式释放锁可以避免删除别的客户端获取成功的锁。

看下基于cloudsop提供的redis是如果工作的

#### redis集群下锁的工作原理

在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们假设有5个Redis master节点，这样保证他们不会同时都宕掉。

1. 获取当前Unix时间，以毫秒为单位。
2. 依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。
3. 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
4. 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
5. 如果因为某些原因，获取锁失败（*没有*在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。

### Zookeeper

http://www.imooc.com/article/284956?block_id=tuijian_wz



http://www.redis.cn/topics/distlock.html